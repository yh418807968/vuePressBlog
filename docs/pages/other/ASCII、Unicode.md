## 为什么需要编码？
计算机的存储器唯一可以存储的就是比特，因此所有文件最终都必须保存为二进制，为了将数据转换为二进制，我们需要对其进行编码，因此需要一套合适的编码机制。

## ASCII码
早期，需要保存的数据还比较简单，基本就是文本数据，包括字母、数字和标点符号，因此只需要对这三种类型文本进行编码即可。

首先，看看我们需要对哪些字符编码：所有的大小字母加起来一共52个编码，0~9数字需要10个编码，一共62个，如果算上一些标点符号，则会超过64 = 2^6个，但无论如何基本上也很难超过128 = 2^7个，因此我们需要的编码机制的位数为7最合适。

**ASCII(American Standard Code for Information Interchange)便是按此标准设计，采用7位编码，**它的二进制取值范围为0000000 ~ 1111111，对应于十六进制就是00h ~ 7Fh。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gdr75tjlnuj30mh0p3q5g.jpg)

上面提到的字母、数字和标点符号一共95个，还有33个控制字符，它们用来执行某一特定功能。

有了ASCII码，字符就可以转为一个对应的编号，从而转为二进制。
比如：
```
Hello you!
```
转为ASCII码，用十六进制表示为：
```
48 65 6C 6F 2C 20 79 6F 75 21
```

## Unicode码
尽管ASCII码是计算机领域最重要的标准，但是它并不是十全十美的。它的问题就蕴藏在它的名字中——American Standard Code for Information Interchange，它太美国化了，即使那些以英语为主要语言的国家，也不完全适用。比如ASCII码中包含美元符号$，但不包含英镑符号，因此就更别谈希腊文（Greek）、阿拉伯文（Arabic）这些欧洲国家了，像中国、日本这些象形文字的国家就更不用说了，7位编码的机制绝对无法满足全世界各种语言的文字。

大多数计算机采用8位编码来存储字符，因此我们自然而然的想到设计一种扩展的ASCII字符集，这样可以包含256个字符，实际上确实就这样的字符集，有的采用双字节字符编码的方式，甚至对额外的6000个字符进行编码，但各字符集的不同版本等各种问题，导致这些字符集不能被广泛使用。

业界一直的目标是希望建立一个独一无二的字符编码系统，它可以用于世界上的所有语言文字，Unicode码应用而生。

Unicode（Universal Multiple-Octet Coded Character Set），通用多八位编码字符集，重点就是Universe Code，即通用编码标准。
Unicode采用16位编码，每一个字符需要2个字节，总共可以表示65536=2^17个字符，可以满足全世界的语言文字。

Unicode的前128个字符编码与ASCII码是一致的，这一点很好理解，它本来就是基于ASCII码而衍生的产物。由于Unicode采用2字节存储一个字符，因此它所占的存储空间也更多，采用ASCII存储需要1MB的数据，采用Unicode编码需要约2MB。为了使编码系统兼容，Unicode在存储空间上付出了相应的代价。

## 参考
《编码》第20章
